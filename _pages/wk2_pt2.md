---
Title: Week Two Part Two
Author: Jeremy R. Groves
---

# Week Two - Part Two

## Working with Census Data via API

Specifically the census data that we are going to working with is the ACS or American Community Survey. This is data collected by the Census every year and is used to fill in the gaps bewteen the full 10-year census carried out. In short, they do sample surveys of areas and utilize statistics to infer the population level statistics and then report them, at various geographic levels, along with the margin of error. While the data is collected every year, the more detailed the geographic unit being reported, the more survey years that are merged and reported. For example, State and National data are released every year; however, census tract or census block group data is reported every year but the data is a five-year moving average. 

Another advantage of using this datasource is that is already linked to geographic information system data so we can also use these files to draw maps as a means of visualizing the data we get. So our first exercise to learn how to use an API and work with data is to create a map showing the percentage of the median rent to the median income by county in the state of Illinois. 

### *Tidycensus* Package

First we start by installing the *tidycensus* pacakge to our machine because we will need that. Secondly, we need to let the U.S> Census Beurua know who we are by registering and obtaining an API Key. This is free and is simply a means of keeping tabs on who is accessing the database for what use. To obtain a key, go to the [https://api.census.gov/data/key_signup.html](Census Key Website) and fill in your name, email address and agree to the terms of service. Your key will now be sent to you in your email account. While we wait for that email to arrive, we need to setup R Studio to install the key into our R base code so that we do not have to input it everytime we want to utilize the Census API. 

In the console, run the following two lines of code (they will run as soon as you hit enter):
```R
library(tidycensus)
census_api_key("key", overwrite = FALSE, install = TRUE)
```
You just want to make sure that where the code says "key" you input the key you recieved in your email. This line of code is instructing R to install this key so you can use the Census API anytime you need it. If you ever need to replace the key, you simply set "overwrite" to TRUE.

The syntax of the *tidycensus* package is based on an API call and you can choose from two different sources at this time: "acs" and "decinial". The former is what we will use and the latter is the data from the 10-year population census. The ACS data only goes back to about 2001 (depending on the level you are looking for) and the decinial API only have 1990, 2000, 2010, and some 2020 data. The basic command we will be using is:
```R
acs <- get_acs(geography = "county",	#defines geography level of data 
               variables = vars,	#specifics the data we want 
               state = 17,	        #denotes the specific state 
               year = 2021,	        #denotes the year
               geometry = TRUE)	#downloads the TIGER shapefile data  
```
The command `get_acs` is the command to pull data from the ACS API and then we have to fill in the necessary elements to help the software find our data. The first is `geography` and this denotes what level of analysis we want. What we put here will dictate which of the surveys (1-Year of 5-Year) the API will pull from. Next we have our `varaibles` and we will return to that momentarily. Notice, however, that rather than a character string, we have an object here because we have defined an object previously that gives a list of the varaibles we want. We do this for simplicity and to limit out calls to the API. Next up we have our `state` and notice that we have a number, not a name or an object. Every geographic level of analysis that the census (and most every other federal data source created) as a unique identifier called FIPS Code. The FIPS stands for Federal Information Processing System and the code can be from two to (I think) thirteen characters long with the longer codes referencing more fine level data. For example, DeKalb County has a FIPS code of 017037 with the first three numbers indicating the state (Illinois and the leading zero is usually dropped) and the next three indicate the county (DeKalb County). If we looked at finer levels within the county, we would see additional values added to this code to inditify them. Based on this information, we can see that we are looking for the state of Illinois by using its FIPS code of 17. Next we have the `year` and this indicates what year were want the data from. We are asking for data from 2021 and, except for the 1-Year data files, this is the most recent that has been released at this point. Since we will be pulling from the 5-Year data files, we know that the data is from the surveyes dating from 2021, 2020, 2019, 2018, and 2017. Finally we have a command `geometry` and it is a logical arguement set to "TRUE". This will pull the necessary data to create polygons for each county. If we only want the data, we can set to this FALSE, but since we want to visualize the data we will keep it set to TRUE.

Just a comment about that is NOT here. For example, we have no entry for `county` and this is because we want all counties within our state. If we only wanted a subset of counties, we could either create a character vector with the FIPS codes for the counties we want or listed their names (however, FIPS code ensure fewer errors). Another case where we might need a county is if we choose "block group" as our geography level. Block Groups are a unit comprise of several census blocks and when one combines several block groups, one gets the census tract. For example, inside of DeKalb County, there are twenty-one census tracts composed of sixty block groups. The FIPS code for block group 4 within census tract 9 of DeKalb County is 170370009004. Breaking this down, we have "17" as the state, "037" as the county, "0009" as the census tract and "004" as the block group. If we were to simply replace "county" with "block group" in the above code, we would download the entire set of blockgroups for the entire state of Illinois (a dataset with 9,691 observations).

### Variables and the Census  

The U.S. Census has data on several different aspects of american life, but they can mainly be broken down into demographic characteristics (items about the people in the population) and housing characteristics (items about the structures in the built enviornment). Finding the "name" of the data that you want is not necessarily the easiest thing to do, but there area  few tools to help you. One is to use the [https://data.census.gov/table/](Census website data center) and use this to search for your data. Since we want to utilize R and R-Studio, we are going to use the *tidycensus* and *tidyverse* to help us find our data. To do this, let's start a script and after clearing our environment, load the two packages *tidycensus* and *tidyverse*. Next, type in the following code and then run your script.
```R
var <- load_varaibles(2021, "acs5", cache = TRUE)
```
After you do this, you should have an object inside your environment called **var** with about 27,886 observationsand 4 columns. This the complete list of everything we can call up from the 2021 ACS 5-Year datafile at every possible geographic level. We want to limit this down to two items: "Median Income" and "Median Rent". To do this, we fill first call up `head(var)` and we see that the "Name" is a alphanumeric code staring with "B" and then we see "lable" and "concept" which each tells us about the variable. We are going to exploit the "concept" column and use our `filter()` and `grepl()` commands to filter our **var** object to only those that contain the phrase "median income". Recall that R is case sensitive so we need to note that the text in the "concept" column is in all caps so we need to replicate that in our code. Specifically, the code will be:
```R
data <- var %>%
    filter(grepl("MEDIAN INCOME", concept))
```
This code uses our pipped coding technique telling R to create a new object called **data** that uses the object **var** and then limit it to only those cases in "concept" where the text string "MEDIAN INCOME" exists. This creates an object with 46 observations. If we double-click the **data** object, it will open in our data viewer and once we adjust the column widths, we see the following:
![image](https://github.com/jrgroves/ECON691/assets/52717006/5df016f5-2e04-4f4d-abcb-d820e66f75c9)
We do not want the observations for Puerto Rico and it looks like the most comprehsive measure we can find would be named "B06001". Notice that there are subgroups under that name with different measures. Specifically, "B06001_001" is the data on the Median Income of all Americans that is adjusted to 2021 dollars while "B06001_002" is the same, but only for individual born in the same state where they current reside. Depending on the question you are asking, you might need these other subgroups. Since we have found part of what we are looking for, go back to our script, and under the point were we loaded the library, let's create an object called **variable** and for now assign it the text string "B06001_001".

We will find the median rent the same way; however, this will also demostrait that the process does take some trial-and-error sometimes. To see this, replace the "MEDIAN INCOME" in the code that filters our variable list from the ACS with "MEDIAN RENT" and then run the code. We see the resulting output has zero observations. The next iterration might be to replace "MEDIAN RENT" with just "RENT" and when we do this we get back almost 2,000 observations that we have to look through. To see if we can narrow this down further, remember that the idea of pipped coding it to essentially say to R, "do this and then, with what you get, do this next thing". Toward that end, let's add a line of code that filters the results when we look for the world "RENT" to then look for the word "MEDIAN". To do this, add another pipped character (`%>%`) and then the code `filter(grepl("MEDIAN", concept))`. Run that and we are down to only 68 observations. 

Another thing you must be careful with when pull down data is to make sure you know what it is you are pulling down. Looking through these data points you will see two possibilities stick out; "MEDIAN GROSS RENT" and "MEDIAN CONTRACT RENT". So what is the difference? This is where the documentation for datasets and databases comes in handy. However, looking direcly for the ACS 5-Year documentation, we can just google search the term and we will see that the former includes the cost of utilitiles while the latter contains only the lease price of rent. This is where you make a judgement call as to what better captures what you are looking for. In our case, we want to focus on the lease rent under the assumption that individuals have some control over their utility bills using alternative means of keep warm or cool, and we see that the name of that is "B25058_001". Let's add this to our script in our **variable** object. The code should be: `variable <- c("B06001_001", "B25058_001")`  

With these defined our are variables, we can now run our code to access the Census API and pull down this data, at the county level, for the State of Illinois in 2021. We do this using our `get_acs()` code located further up this page. This this is complete, you can check your data using the `head(acs)` command and you should have a dataframe with 204 Observations and 6 variables. You should also see in your console information about the grography of the data because this called an "sf" object that can also be linked geogrphically to other datasets.

(Click for next step)[wk2_pt3.md]
